{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPooling2D, Conv2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4927 images belonging to 2 classes.\n",
      "Found 542 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(300, 300)\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(300, 300),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 1022s 8s/step - loss: 0.6046 - acc: 0.7790 - val_loss: 0.5757 - val_acc: 0.8221\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 919s 7s/step - loss: 0.4425 - acc: 0.8325 - val_loss: 0.7910 - val_acc: 0.8346\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 921s 7s/step - loss: 0.3649 - acc: 0.8584 - val_loss: 0.6619 - val_acc: 0.8668\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 933s 7s/step - loss: 0.3273 - acc: 0.8690 - val_loss: 1.3092 - val_acc: 0.6353\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 939s 8s/step - loss: 0.2921 - acc: 0.8814 - val_loss: 0.2749 - val_acc: 0.9083\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 945s 8s/step - loss: 0.2908 - acc: 0.8900 - val_loss: 0.4708 - val_acc: 0.7769\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 951s 8s/step - loss: 0.2638 - acc: 0.8975 - val_loss: 0.3487 - val_acc: 0.8957\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 943s 8s/step - loss: 0.2666 - acc: 0.9085 - val_loss: 0.2004 - val_acc: 0.9298\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 945s 8s/step - loss: 0.2311 - acc: 0.9115 - val_loss: 1.8571 - val_acc: 0.5364\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 951s 8s/step - loss: 0.2323 - acc: 0.9090 - val_loss: 0.6615 - val_acc: 0.7644\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 953s 8s/step - loss: 0.2146 - acc: 0.9240 - val_loss: 0.3136 - val_acc: 0.8518\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 941s 8s/step - loss: 0.2142 - acc: 0.9170 - val_loss: 0.2916 - val_acc: 0.8734\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 939s 8s/step - loss: 0.2030 - acc: 0.9230 - val_loss: 0.2357 - val_acc: 0.9108\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 942s 8s/step - loss: 0.1792 - acc: 0.9270 - val_loss: 0.4332 - val_acc: 0.7581\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 944s 8s/step - loss: 0.1802 - acc: 0.9325 - val_loss: 0.3032 - val_acc: 0.8455\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 940s 8s/step - loss: 0.1693 - acc: 0.9360 - val_loss: 0.2787 - val_acc: 0.9135\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 944s 8s/step - loss: 0.2014 - acc: 0.9205 - val_loss: 0.5230 - val_acc: 0.7023\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 945s 8s/step - loss: 0.1553 - acc: 0.9430 - val_loss: 0.4611 - val_acc: 0.8810\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 943s 8s/step - loss: 0.1622 - acc: 0.9380 - val_loss: 2.0034 - val_acc: 0.5363\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 970s 8s/step - loss: 0.1723 - acc: 0.9360 - val_loss: 0.2645 - val_acc: 0.9234\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 940s 8s/step - loss: 0.1505 - acc: 0.9425 - val_loss: 0.2253 - val_acc: 0.9273\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 944s 8s/step - loss: 0.1610 - acc: 0.9355 - val_loss: 0.1580 - val_acc: 0.9296\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 942s 8s/step - loss: 0.1437 - acc: 0.9420 - val_loss: 2.9237 - val_acc: 0.7356\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 941s 8s/step - loss: 0.1514 - acc: 0.9425 - val_loss: 0.1870 - val_acc: 0.9322\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 941s 8s/step - loss: 0.1370 - acc: 0.9485 - val_loss: 0.7176 - val_acc: 0.7293\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 943s 8s/step - loss: 0.1238 - acc: 0.9495 - val_loss: 0.1631 - val_acc: 0.9548\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 944s 8s/step - loss: 0.1479 - acc: 0.9505 - val_loss: 0.2040 - val_acc: 0.9436\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 941s 8s/step - loss: 0.1221 - acc: 0.9549 - val_loss: 0.3932 - val_acc: 0.8379\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 933s 7s/step - loss: 0.1156 - acc: 0.9580 - val_loss: 0.1128 - val_acc: 0.9511\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 937s 7s/step - loss: 0.1378 - acc: 0.9505 - val_loss: 0.1091 - val_acc: 0.9673\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 927s 7s/step - loss: 0.1089 - acc: 0.9585 - val_loss: 0.1772 - val_acc: 0.9511\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 929s 7s/step - loss: 0.1218 - acc: 0.9565 - val_loss: 0.2270 - val_acc: 0.9259\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 932s 7s/step - loss: 0.1079 - acc: 0.9635 - val_loss: 0.7372 - val_acc: 0.6729\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 935s 7s/step - loss: 0.1202 - acc: 0.9555 - val_loss: 0.1904 - val_acc: 0.9435\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 931s 7s/step - loss: 0.1123 - acc: 0.9590 - val_loss: 0.2144 - val_acc: 0.9386\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 955s 8s/step - loss: 0.1128 - acc: 0.9580 - val_loss: 0.1047 - val_acc: 0.9662\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 924s 7s/step - loss: 0.0827 - acc: 0.9685 - val_loss: 0.5072 - val_acc: 0.9083\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 922s 7s/step - loss: 0.0959 - acc: 0.9655 - val_loss: 0.4171 - val_acc: 0.8484\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 923s 7s/step - loss: 0.1119 - acc: 0.9585 - val_loss: 0.2365 - val_acc: 0.9221\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 935s 7s/step - loss: 0.1060 - acc: 0.9594 - val_loss: 0.1846 - val_acc: 0.9261\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 927s 7s/step - loss: 0.0826 - acc: 0.9670 - val_loss: 0.6583 - val_acc: 0.7563\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 923s 7s/step - loss: 0.1059 - acc: 0.9675 - val_loss: 1.0121 - val_acc: 0.6955\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 920s 7s/step - loss: 0.0759 - acc: 0.9700 - val_loss: 0.9962 - val_acc: 0.7349\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 928s 7s/step - loss: 0.0888 - acc: 0.9700 - val_loss: 0.1084 - val_acc: 0.9599\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 929s 7s/step - loss: 0.0754 - acc: 0.9750 - val_loss: 1.0690 - val_acc: 0.8693\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 924s 7s/step - loss: 0.0778 - acc: 0.9705 - val_loss: 0.2263 - val_acc: 0.9436\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 925s 7s/step - loss: 0.1105 - acc: 0.9625 - val_loss: 0.3769 - val_acc: 0.7877\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 928s 7s/step - loss: 0.0759 - acc: 0.9710 - val_loss: 0.6827 - val_acc: 0.8521\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 933s 7s/step - loss: 0.0986 - acc: 0.9685 - val_loss: 0.3276 - val_acc: 0.8568\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 927s 7s/step - loss: 0.0856 - acc: 0.9694 - val_loss: 0.2105 - val_acc: 0.9649\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "\n",
    "model.save(\"model2-added-dropout.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
